{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  8 09:21:03 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   56C    P0   171W / 250W |  32322MiB / 32480MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from RandAugment import RandAugment\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import time\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unable-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  \n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "characteristic-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "upset-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './input/data/eval/images/'\n",
    "df_test = pd.read_csv('./input/data/eval/info.csv')\n",
    "\n",
    "test_img_paths = []\n",
    "    \n",
    "for path in df_test['ImageID'].tolist():\n",
    "    test_img_paths.append(test_path+path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funky-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.CenterCrop((300, 230)),\n",
    "                                      transforms.Resize((224, 224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                     ])\n",
    "test_transforms2 = transforms.Compose([\n",
    "                                      transforms.Resize((224, 224), Image.BILINEAR),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)),\n",
    "                                     ])\n",
    "\n",
    "test_dataset = TestDataset(test_img_paths, transform=test_transforms) \n",
    "test_dataset2 = TestDataset(test_img_paths, transform=test_transforms2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "together-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "# test_loader2 = DataLoader(test_dataset2, batch_size=256, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-hotel",
   "metadata": {},
   "source": [
    "# 각 Task Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thousand-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "RANDOM_SEED = 1\n",
    "BATCH_SIZE = 256\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "third-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "## Multi Model\n",
    "lr = 7e-5\n",
    "\n",
    "# ModelA = mask, ModelB = age, ModelC = gender\n",
    "modelA = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelA_1 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelA_2 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelB_1 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelB_2 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelB_3 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelB_4 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelB_5 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 3)\n",
    "modelC = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 2)\n",
    "modelC_1 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 2)\n",
    "# modelC_2 = EfficientNet.from_pretrained('efficientnet-b4', num_classes = 2)\n",
    "\n",
    "# modelA._fc = nn.Linear(1792, 3)\n",
    "# modelB_1._fc = nn.Linear(1792, 3)\n",
    "# modelB_2._fc = nn.Linear(1792, 3)\n",
    "# modelB_3._fc = nn.Linear(1792, 3)\n",
    "# modelC._fc = nn.Linear(1792, 2)\n",
    "\n",
    "PATH_A = './checkpoint/mask_model(eff_b4(n737))/best_model.pt'\n",
    "PATH_A_1 = './checkpoint/mask_model(eff_b4(n1062))/best_model.pt'\n",
    "PATH_A_2 = './checkpoint/mask_model(eff_b4(noR_n737))/best_model.pt'\n",
    "PATH_B_1 = './checkpoint/age_model(eff_b4_(noR_n0))/best_model.pt'\n",
    "PATH_B_2 = './checkpoint/age_model(eff_b4_softlabe(n1062 s1))/best_model.pt'  ##\n",
    "PATH_B_3 = './checkpoint/age_model(eff_b4_(noR_n1062))/best_model.pt'\n",
    "PATH_B_4 = './checkpoint/age_model(eff_b4_softlabel2)/best_model.pt'  ##\n",
    "PATH_B_5 = './checkpoint/age_model(eff_b4_(noR_n1400))/best_model.pt'  ##\n",
    "PATH_C = './checkpoint/gender_model(eff_b4)/best_model_EPOCH190.pt'\n",
    "PATH_C_1 = './checkpoint/gender_model(eff_b4_n1062)/best_model.pt'\n",
    "# PATH_C_2 = './checkpoint/gender_model(eff_b4)/best_model_EPOCH147.pt'\n",
    "\n",
    "checkpointA = torch.load(PATH_A)\n",
    "checkpointA_1 = torch.load(PATH_A_1)\n",
    "checkpointA_2 = torch.load(PATH_A_2)\n",
    "checkpointB_1 = torch.load(PATH_B_1)\n",
    "checkpointB_2 = torch.load(PATH_B_2)\n",
    "checkpointB_3 = torch.load(PATH_B_3)\n",
    "checkpointB_4 = torch.load(PATH_B_4)\n",
    "checkpointB_5 = torch.load(PATH_B_5)\n",
    "checkpointC = torch.load(PATH_C)\n",
    "checkpointC_1 = torch.load(PATH_C_1)\n",
    "checkpointC_2 = torch.load(PATH_C_1)\n",
    "\n",
    "modelA.load_state_dict(checkpointA)\n",
    "modelA.cuda()\n",
    "modelA_1.load_state_dict(checkpointA_1)\n",
    "modelA_1.cuda()\n",
    "modelA_2.load_state_dict(checkpointA_2)\n",
    "modelA_2.cuda()\n",
    "modelB_1.load_state_dict(checkpointB_1)\n",
    "modelB_1.cuda()\n",
    "modelB_2.load_state_dict(checkpointB_2)\n",
    "modelB_2.cuda()\n",
    "modelB_3.load_state_dict(checkpointB_3)\n",
    "modelB_3.cuda()\n",
    "modelB_4.load_state_dict(checkpointB_4)\n",
    "modelB_4.cuda()\n",
    "modelB_5.load_state_dict(checkpointB_5)\n",
    "modelB_5.cuda()\n",
    "modelC.load_state_dict(checkpointC)\n",
    "modelC.cuda()\n",
    "modelC_1.load_state_dict(checkpointC_1)\n",
    "modelC_1.cuda()\n",
    "# modelC_2.load_state_dict(checkpointC_2)\n",
    "# modelC_2.cuda()\n",
    "\n",
    "# Freeze the feature extracting convolution layers\n",
    "for param in modelA.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelA_1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelA_2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_4.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_5.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelC.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelC_1.parameters():\n",
    "    param.requires_grad = False\n",
    "# for param in modelC_2.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unknown-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Multi Model\n",
    "# lr = 7e-5\n",
    "\n",
    "# # ModelA = mask, ModelB = age, ModelC = gender\n",
    "# modelA = timm.create_model('ecaresnet50d_pruned', pretrained=True)\n",
    "# modelB = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "# modelC = timm.create_model('ecaresnet50d_pruned', pretrained=True)\n",
    "\n",
    "# modelA.fc = nn.Linear(2022, 3)\n",
    "# modelB._fc = nn.Linear(1792, 3)\n",
    "# modelC.fc = nn.Linear(2022, 2)\n",
    "\n",
    "# PATH_A = './checkpoint/mask_model/best_model_EPOCH8.pt'\n",
    "# PATH_B = './checkpoint/age_model(eff_b4_softlabel2)/best_model.pt'\n",
    "# PATH_C = './checkpoint/gender_model/best_model_EPOCH34.pt'\n",
    "\n",
    "# checkpointA = torch.load(PATH_A)\n",
    "# checkpointB = torch.load(PATH_B)\n",
    "# checkpointC = torch.load(PATH_C)\n",
    "\n",
    "# modelA.load_state_dict(checkpointA)\n",
    "# modelA.cuda()\n",
    "# modelB.load_state_dict(checkpointB)\n",
    "# modelB.cuda()\n",
    "# modelC.load_state_dict(checkpointC)\n",
    "# modelC.cuda()\n",
    "\n",
    "# # Freeze the feature extracting convolution layers\n",
    "# for param in modelA.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in modelB.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in modelC.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reasonable-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuliModel(nn.Module):\n",
    "    def __init__(self, modelA, modelA_1, modelA_2, modelB_1, modelB_2, modelB_3, modelB_4, modelB_5, modelC, modelC_1):\n",
    "        super(MuliModel, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.modelA = modelA\n",
    "        self.modelA_1 = modelA_1\n",
    "        self.modelA_2 = modelA_2\n",
    "        self.modelB_1 = modelB_1\n",
    "        self.modelB_2 = modelB_2\n",
    "        self.modelB_3 = modelB_3\n",
    "        self.modelB_4 = modelB_4\n",
    "        self.modelB_5 = modelB_5\n",
    "        self.modelC = modelC\n",
    "        self.modelC_1 = modelC_1\n",
    "#         self.modelC_2 = modelC_2\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.FC_layer = nn.Linear(8, 18)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.classifier = nn.Linear(18, 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.softmax(self.modelA(x))\n",
    "        x1_1 = self.softmax(self.modelA_1(x))\n",
    "        x1_2 = self.softmax(self.modelA_2(x))\n",
    "        \n",
    "        x2_1 = self.softmax(self.modelB_1(x))\n",
    "        x2_2 = self.softmax(self.modelB_2(x))\n",
    "        x2_3 = self.softmax(self.modelB_3(x))\n",
    "        x2_4 = self.softmax(self.modelB_4(x))\n",
    "        x2_5 = self.softmax(self.modelB_5(x))\n",
    "        \n",
    "        x3_1 = self.softmax(self.modelC(x))\n",
    "        x3_2 = self.softmax(self.modelC_1(x))\n",
    "#         x3_3 = self.softmax(self.modelC_2(x))\n",
    "        \n",
    "        x1 = torch.argmax(x1 * 0.6 + x1_2 * 0.6 + x1_2 * 1.2, 1)\n",
    "        x2 = torch.argmax(x2_1 + x2_2 * 0.3 + x2_3 + x2_4 * 0.3 + x2_5, 1)\n",
    "        x3 = torch.argmax(x3_1 + x3_2, 1)\n",
    "        label_pred = x1 * 6 + x3 * 3 + x2        \n",
    "        return label_pred\n",
    "\n",
    "model = MuliModel(modelA, modelA_1, modelA_2, modelB_1, modelB_2, modelB_3, modelB_4, modelB_5, modelC, modelC_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "established-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "loader = test_loader\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model(images)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv('./submission.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "professional-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1],[1],[0],[1],[0]])\n",
    "b = torch.tensor([[2],[3],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "european-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 3],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, b), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-palestinian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "steady-navigator",
   "metadata": {},
   "source": [
    "# Augmentation 다르게 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nervous-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "refined-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 256\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-transition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "reduced-cedar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "model_cls = getattr(import_module(\"baseline.model\"), 'Efficientnet_b4')\n",
    "modelD = model_cls(num_classes = 3)\n",
    "PATH_D = './baseline/model/Efficientnet_b4_adam_lr7e5_resi244/best.pth'\n",
    "checkpointD = torch.load(PATH_D)\n",
    "modelD.load_state_dict(checkpointD)\n",
    "modelD.cuda()\n",
    "for param in modelD.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model_cls = getattr(import_module(\"baseline.model\"), 'Efficientnet_b4')\n",
    "modelE = model_cls(num_classes = 3)\n",
    "PATH_E = './baseline/model/Efficientnet_b4_adam_lr8e5_resi244/best.pth'\n",
    "checkpointE = torch.load(PATH_E)\n",
    "modelE.load_state_dict(checkpointE)\n",
    "modelE.cuda()\n",
    "for param in modelE.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "logical-chamber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "model_cls = getattr(import_module(\"baseline.model\"), 'Efficientnet_b4')\n",
    "modelB_1 = model_cls(num_classes = 3)\n",
    "PATH_B_1 = './baseline/model/Efficientnet_b4_adam_lr6e5_resi244/best.pth'\n",
    "checkpointB_1 = torch.load(PATH_B_1)\n",
    "modelB_1.load_state_dict(checkpointB_1)\n",
    "modelB_1.cuda()\n",
    "for param in modelB_1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "regular-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_cls = getattr(import_module(\"baseline.model\"), 'Efficientnet_b4')\n",
    "modelF = model_cls(num_classes = 3)\n",
    "PATH_F = './baseline/model/Efficientnet_b4_adam_lr6e5_okay/best.pth'\n",
    "checkpointF = torch.load(PATH_F)\n",
    "modelF.load_state_dict(checkpointF)\n",
    "modelF.cuda()\n",
    "for param in modelF.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "verbal-proof",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "## Multi Model\n",
    "lr = 7e-5\n",
    "model_cls = getattr(import_module(\"baseline.model\"), 'Efficientnet_b4')\n",
    "# ModelA = mask, ModelB = age, ModelC = gender\n",
    "modelA = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "modelB_1 = model_cls(num_classes = 3)\n",
    "modelB_2 = model_cls(num_classes = 3)\n",
    "modelB_3 = model_cls(num_classes = 3)\n",
    "modelC = EfficientNet.from_pretrained('efficientnet-b4')\n",
    "\n",
    "modelA._fc = nn.Linear(1792, 3)\n",
    "\n",
    "modelC._fc = nn.Linear(1792, 2)\n",
    "\n",
    "PATH_A = './checkpoint/mask_model(eff_b4(n737))/best_model.pt'\n",
    "PATH_B_1 = './baseline/model/Efficientnet_b4_adam_lr6e5_resi244/best.pth'\n",
    "PATH_B_2 = './baseline/model/Efficientnet_b4_adam_lr7e5_resi244/best.pth'\n",
    "PATH_B_3 = './baseline/model/Efficientnet_b4_adam_lr8e5_resi244/best.pth' \n",
    "PATH_C = './checkpoint/gender_model(eff_b4)/best_model_EPOCH190.pt'\n",
    "\n",
    "checkpointA = torch.load(PATH_A)\n",
    "checkpointB_1 = torch.load(PATH_B_1)\n",
    "checkpointB_2 = torch.load(PATH_B_2)\n",
    "checkpointB_3 = torch.load(PATH_B_3)\n",
    "checkpointC = torch.load(PATH_C)\n",
    "\n",
    "modelA.load_state_dict(checkpointA)\n",
    "modelA.cuda()\n",
    "modelB_1.load_state_dict(checkpointB_1)\n",
    "modelB_1.cuda()\n",
    "modelB_2.load_state_dict(checkpointB_2)\n",
    "modelB_2.cuda()\n",
    "modelB_3.load_state_dict(checkpointB_3)\n",
    "modelB_3.cuda()\n",
    "modelC.load_state_dict(checkpointC)\n",
    "modelC.cuda()\n",
    "\n",
    "# Freeze the feature extracting convolution layers\n",
    "for param in modelA.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_2.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelB_3.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in modelC.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "friendly-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 왜인지 모르겠지만 eval은 하면 안되는것 갇음\n",
    "\n",
    "class AgeModel(nn.Module):\n",
    "    def __init__(self, modelB_1, modelB_2, modelB_3):\n",
    "        super(AgeModel, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.modelB_1 = modelB_1\n",
    "        self.modelB_2 = modelB_2\n",
    "        self.modelB_3 = modelB_3\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2_1 = self.softmax(self.modelB_1(x))\n",
    "        x2_2 = self.softmax(self.modelB_2(x))\n",
    "        x2_3 = self.softmax(self.modelB_3(x))\n",
    "        \n",
    "        x2 = torch.argmax(x2_1 + x2_2 + x2_3, 1)\n",
    "#         x2 = torch.argmax(x2_2 + x2_3, 1)\n",
    "        return x2\n",
    "\n",
    "model_Age = AgeModel(modelB_1, modelB_2, modelB_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fifty-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderMaskModel(nn.Module):\n",
    "    def __init__(self, modelA, modelC):\n",
    "        super(GenderMaskModel, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.modelA = modelA\n",
    "        self.modelC = modelC\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = torch.argmax(self.modelA(x), 1)\n",
    "        x3 = torch.argmax(self.modelC(x), 1)\n",
    "        label_pred = x1 * 6 + x3 * 3   \n",
    "        return label_pred\n",
    "\n",
    "model_MaskGender = GenderMaskModel(modelA, modelC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "social-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age predict complite\n",
      "Mask and Gender predict complite\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "loader_age = test_loader2\n",
    "loader_MaskGender = test_loader\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model_Age = model_Age.to(DEVICE)\n",
    "# model_Age.eval()\n",
    "\n",
    "model_MaskGender = model_MaskGender.to(DEVICE)\n",
    "model_MaskGender.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "# all_predictions = []\n",
    "age_predictions = []\n",
    "maskgeder_predictions = []\n",
    "for images in loader_age:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model_Age(images)\n",
    "        age_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(\"Age predict complite\")\n",
    "        \n",
    "for images in loader_MaskGender:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model_MaskGender(images)\n",
    "        maskgeder_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(\"Mask and Gender predict complite\")        \n",
    "\n",
    "all_predictions = np.array(age_predictions) + np.array(maskgeder_predictions)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join('./', 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tough-acrylic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dominant-fairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maskgeder_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "emotional-acceptance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confident-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "separate-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "expected-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskgeder_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "contemporary-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spread-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "exotic-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskSplitByProfileDataset(data_dir='/opt/ml/input/data/train/images',\n",
    "                                   \n",
    "        n=0,\n",
    "        k=1,\n",
    "        val_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "tutorial-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "demonstrated-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = BaseAugmentation(\n",
    "    resize=(244, 244),\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "\n",
    "transform_val = BaseAugmentation(\n",
    "    resize=(244, 244),\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "dataset.set_transform(transform, transform_val)\n",
    "\n",
    "# -- data_loader\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=64,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sonic-insert",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Efficientnet_b4(\n",
       "  (model): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (26): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (27): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (29): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.4, inplace=False)\n",
       "    (_fc): Linear(in_features=1792, out_features=3, bias=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "unable-revelation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating validation results...\n"
     ]
    }
   ],
   "source": [
    "modelB_1.eval()\n",
    "with torch.no_grad():\n",
    "    print(\"Calculating validation results...\")\n",
    "    modelB_1.eval()\n",
    "    val_loss_items = []\n",
    "    val_acc_items = []\n",
    "    val_f1_pred = []\n",
    "    val_f1_y = []\n",
    "    acc_okay = 0\n",
    "    count_all = 0\n",
    "    for val_batch in val_loader:\n",
    "        inputs, labels, levels = val_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        levels = levels.to(device)\n",
    "\n",
    "        outs = modelB_1(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "        acc_item = (labels == preds).sum().item()\n",
    "\n",
    "        val_f1_pred += preds.tolist()\n",
    "        val_f1_y += labels.tolist()\n",
    "\n",
    "        val_acc_items.append(acc_item)\n",
    "        acc_okay += acc_item\n",
    "        count_all += len(preds)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "given-montgomery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0288, -0.0122, -0.0122,  ..., -0.5252, -0.5252, -0.5583],\n",
       "          [-0.0122, -0.0122,  0.0043,  ..., -0.5086, -0.5252, -0.5583],\n",
       "          [ 0.0043,  0.0043,  0.0043,  ..., -0.4590, -0.4590, -0.4590],\n",
       "          ...,\n",
       "          [-1.2036, -1.2863, -1.2532,  ..., -1.0712, -1.2202, -1.8158],\n",
       "          [-1.7331, -1.5676, -1.4684,  ..., -0.7734, -0.9720, -1.3856],\n",
       "          [-1.9151, -1.8655, -1.9648,  ..., -0.7568, -1.0547, -1.0381]],\n",
       " \n",
       "         [[ 0.4363,  0.4522,  0.4522,  ..., -0.8815, -0.8815, -0.9132],\n",
       "          [ 0.4522,  0.4522,  0.4680,  ..., -0.8656, -0.8815, -0.9132],\n",
       "          [ 0.4680,  0.4680,  0.4680,  ..., -0.8180, -0.8180, -0.8180],\n",
       "          ...,\n",
       "          [-0.9609, -1.0244, -0.9609,  ..., -0.7703, -0.9450, -1.5483],\n",
       "          [-1.5801, -1.3895, -1.2466,  ..., -0.4846, -0.7068, -1.1355],\n",
       "          [-1.8341, -1.7706, -1.8023,  ..., -0.4687, -0.7862, -0.7862]],\n",
       " \n",
       "         [[ 0.7310,  0.7469,  0.7469,  ..., -1.4530, -1.4530, -1.4849],\n",
       "          [ 0.7469,  0.7469,  0.7629,  ..., -1.4370, -1.4530, -1.4849],\n",
       "          [ 0.7629,  0.7629,  0.7629,  ..., -1.3892, -1.3892, -1.3892],\n",
       "          ...,\n",
       "          [-1.3254, -1.3573, -1.2457,  ..., -0.9747, -1.1341, -1.6921],\n",
       "          [-1.7877, -1.5805, -1.3892,  ..., -0.7516, -0.9429, -1.3573],\n",
       "          [-1.8834, -1.7877, -1.7718,  ..., -0.7834, -1.0704, -1.0385]]]),\n",
       " 1,\n",
       " tensor([0., 1., 0.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "published-point",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'MaskSplitByProfileDataset' has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7f2014f84894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMaskSplitByProfileDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpahse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'MaskSplitByProfileDataset' has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "ind = []\n",
    "for phase, indices in MaskSplitByProfileDataset.indices.items():\n",
    "    ind = indices\n",
    "    if pahse == \"val\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "engaging-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "capital-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[1,2,3],[2,-1,0.8], [1,-9,-10],[0,0.1,0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "owned-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([[0,4,2],[1,-1,9], [9,-9,-10],[2,0.1,0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "wound-sector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0591e-01, 1.1115e+00, 7.8255e-01],\n",
       "        [7.4054e-01, 3.6898e-02, 1.2226e+00],\n",
       "        [1.9999e+00, 4.5412e-05, 1.6706e-05],\n",
       "        [8.9363e-01, 3.4300e-01, 7.6337e-01]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(b) + a(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "located-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0031e-02, 2.4473e-01, 6.6524e-01],\n",
       "        [7.4020e-01, 3.6853e-02, 2.2294e-01],\n",
       "        [9.9994e-01, 4.5397e-05, 1.6701e-05],\n",
       "        [2.1907e-01, 2.4211e-01, 5.3882e-01]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "former-champagne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5876e-02, 8.6681e-01, 1.1731e-01],\n",
       "        [3.3533e-04, 4.5383e-05, 9.9962e-01],\n",
       "        [1.0000e+00, 1.5230e-08, 5.6028e-09],\n",
       "        [6.7456e-01, 1.0089e-01, 2.2454e-01]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "prepared-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a(b) + a(c), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "official-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age predict complite\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "loader_age = test_loader2\n",
    "loader_age2 = test_loader2\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "model_Age = model_Age.to(DEVICE)\n",
    "model_Age.eval()\n",
    "\n",
    "modelB_1 = modelB_1.to(DEVICE)\n",
    "modelB_1.eval()\n",
    "\n",
    "# modelD = modelD.to(DEVICE)\n",
    "# modelD.eval()\n",
    "\n",
    "# modelE = modelE.to(DEVICE)\n",
    "# modelE.eval()\n",
    "\n",
    "modelF = modelF.to(DEVICE)\n",
    "modelF.eval()\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "# all_predictions = []\n",
    "age_predictions1 = []\n",
    "age_predictions2 = []\n",
    "age_predictions3 = []\n",
    "age_predictions4 = []\n",
    "age_predictions5 = []\n",
    "\n",
    "for images in loader_age:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model_Age(images)\n",
    "        age_predictions1.extend(pred.cpu().numpy())\n",
    "        pred = modelB_1(images)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        age_predictions2.extend(pred.cpu().numpy())\n",
    "#         pred = modelD(images)\n",
    "#         pred = torch.argmax(pred,1)\n",
    "#         age_predictions3.extend(pred.cpu().numpy())\n",
    "#         pred = modelE(images)\n",
    "#         pred = torch.argmax(pred,1)\n",
    "#         age_predictions4.extend(pred.cpu().numpy())\n",
    "        pred = modelF(images)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        age_predictions5.extend(pred.cpu().numpy())\n",
    "        \n",
    "        \n",
    "print(\"Age predict complite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "statewide-release",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "[1, 2, 1, 1, 1, 1, 2, 1, 0, 2]\n",
      "[2, 2, 2, 2, 2, 0, 2, 2, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "# 2번째 차이를 보자 eval 차이\n",
    "print(age_predictions1[:10])\n",
    "print(age_predictions2[:10])\n",
    "print(age_predictions5[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "crazy-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "[1, 2, 1, 1, 1, 1, 2, 1, 0, 2]\n",
      "[2, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(age_predictions1[:10])\n",
    "print(age_predictions2[:10])\n",
    "print(age_predictions5[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "silver-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 0, 1]\n",
      "[2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# 차이를 보자\n",
    "print(age_predictions2[:30])\n",
    "print(age_predictions5[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "significant-victorian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 0, 1]\n",
      "[2, 1, 1, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(age_predictions2[:30])\n",
    "print(age_predictions5[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "downtown-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(age_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprising-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(age_predictions[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "leading-classroom",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age predict complite\n",
      "Mask and Gender predict complite\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "loader_age = test_loader2\n",
    "loader_MaskGender = test_loader\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "modelF = modelF.to(DEVICE)\n",
    "modelF.eval()\n",
    "\n",
    "model_MaskGender = model_MaskGender.to(DEVICE)\n",
    "model_MaskGender.eval()\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "# all_predictions = []\n",
    "age_predictions = []\n",
    "maskgeder_predictions = []\n",
    "for images in loader_age:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = modelF(images)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        age_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(\"Age predict complite\")\n",
    "        \n",
    "for images in loader_MaskGender:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model_MaskGender(images)\n",
    "        maskgeder_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "print(\"Mask and Gender predict complite\")        \n",
    "\n",
    "all_predictions = np.array(age_predictions) + np.array(maskgeder_predictions)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join('./', 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "million-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "loader = test_loader2\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "modelF = modelF.to(DEVICE)\n",
    "modelF.eval()\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "# all_predictions = []\n",
    "age_predictions1 = []\n",
    "age_predictions2 = []\n",
    "age_predictions3 = []\n",
    "age_predictions4 = []\n",
    "age_predictions5 = []\n",
    "\n",
    "for images in loader_age:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(DEVICE)\n",
    "        pred = model_Age(images)\n",
    "        age_predictions1.extend(pred.cpu().numpy())\n",
    "        pred = modelB_1(images)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        age_predictions2.extend(pred.cpu().numpy())\n",
    "#         pred = modelD(images)\n",
    "#         pred = torch.argmax(pred,1)\n",
    "#         age_predictions3.extend(pred.cpu().numpy())\n",
    "#         pred = modelE(images)\n",
    "#         pred = torch.argmax(pred,1)\n",
    "#         age_predictions4.extend(pred.cpu().numpy())\n",
    "        pred = modelF(images)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        age_predictions5.extend(pred.cpu().numpy())\n",
    "        \n",
    "        \n",
    "print(\"Age predict complite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
